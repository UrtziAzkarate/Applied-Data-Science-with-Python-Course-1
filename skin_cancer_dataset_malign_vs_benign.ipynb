{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UrtziAzkarate/Applied-Data-Science-with-Python-Course-1/blob/main/skin_cancer_dataset_malign_vs_benign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edzfgVpTCcLB"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2U9QuQkWdhS",
        "outputId": "913427b4-e4fc-4ee6-bce8-b04300599da7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device : cpu\n"
          ]
        }
      ],
      "source": [
        "# Si tenemos la GPU disponible, utilizamos la GPU para que las imágenes de cada batch se procesen paralelamente de forma más eficiente. De lo contrario utilizamos la CPU disponible.\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device : {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G94bSQTi7yMn",
        "outputId": "fa22c486-c6fa-401c-cbed-53ae1af46366"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Colab cache for faster access to the 'skin-cancer-malignant-vs-benign' dataset.\n",
            "Path to dataset files: /kaggle/input/skin-cancer-malignant-vs-benign\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"fanconic/skin-cancer-malignant-vs-benign\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjo8PwnEvn2Z"
      },
      "source": [
        "**IMPORTAMOS DRIVE PARA PODER CONECTARNOS AL DATASET DESCARGADO DE KAGGLE EN DRIVE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqmJtXh1qkv8",
        "outputId": "3a3405d5-9956-4274-f56b-b17cd4d811b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcjJS4ijS8VK"
      },
      "source": [
        "  **PUNTOS 1 y 2**\n",
        "\n",
        "*   Leemos y cargámos las imágenes en Tensores de PyTorch ya partidos en TRAIN y TEST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGQ2dZ65fY1z"
      },
      "outputs": [],
      "source": [
        "path_train = '/content/drive/MyDrive/MSc Inteligencia Artificial/Modulo 6 - Visión Artificial/Actividades/Actividades Entregables/Skin Cancer: Malign vs Benign/archive/data/train'\n",
        "path_test =  '/content/drive/MyDrive/MSc Inteligencia Artificial/Modulo 6 - Visión Artificial/Actividades/Actividades Entregables/Skin Cancer: Malign vs Benign/archive/data/test'\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=path_train)\n",
        "test_dataset = datasets.ImageFolder(root=path_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UYL6LjdTugS"
      },
      "source": [
        "**PUNTO 2.**\n",
        "\n",
        "*   Divide el conjunto de datos en dos: uno para entrenamiento y otro para test.\n",
        "Esto ya no nos hace falta hacer ya que en origen el dataset viene particionado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx8tJK15QHbk"
      },
      "outputs": [],
      "source": [
        "# train_ratio = 0.8\n",
        "# train_size = int(train_ratio * len(cancer_data))\n",
        "# test_size = len(cancer_data) - train_size\n",
        "# train_dataset, test_dataset = random_split(cancer_data, [train_size, test_size])\n",
        "\n",
        "# print(train_size)\n",
        "# print(test_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUeZhz2Mhje2"
      },
      "source": [
        "**PUNTO 3.**\n",
        "\n",
        "*  Aplicamos técnicas de Data Augmentation como el desplazamiento horizontal y la rotación de ±20°\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPepChyCDPMR"
      },
      "outputs": [],
      "source": [
        "## IMPORTANTE ##\n",
        "# PRIMERO TRANSFORMAMOS EL TRAIN APLICADO DATA AUGMENTATION, DESPUÉS AL TEST NO LE APLICAREMOS EL DATA AUGMENTATION, TAN SOLO LA NORMALIZACIÓN. Ya que el data augmentation se utiliza para entrenar. ##\n",
        "\n",
        "\n",
        "# Comprimimos el tamaño de las imagenes a 224x224 que es una medida estandar que permite:\n",
        "# 1. Entrenar modelos sin perder detalles importantes\n",
        "# 2. Entrenar modelos de forma rápida y óptima\n",
        "\n",
        "# Aplicamos técnicas de aumentación de movimiento horizontal aleatorio de la imágen así como la rotación aleatoria de la imagen en ±20°\n",
        "\n",
        "# Aplicamos una normalización de las variables para que los valores vayan de -1 a 1. Esto nos ayudará a mejorar el aprendizaje del modelo, ya que\n",
        "# Cuando los valores se centran alrededor del 0, los modelos son muchos más eficientes a la hora de aplicar gradientes o funciones de activación como el ReLU, donde los valores negativos (-) se desactivan.\n",
        "\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomHorizontalFlip(p=0.5), # reflejo horizontal aleatorio\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.05)),  # Desplaza la imagen horizontalmente hasta un 10% y verticalmente hasta un 5% de la anchura de la imágen.\n",
        "    transforms.RandomCrop(size=(224, 224), padding=10), # Añadimos un padding de 10 para después recortar la imagen e intentar entrenar el modelo con las zonas más importantes de cada imágen\n",
        "    transforms.RandomRotation(degrees=20), # rotación aleatoria ±20°\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], # Coge cada valor X (que va de 0 a 1 después de haber aplicado el ToTensor) y hace la siguiente ecuación para convertir valores entre -1 y 1: (x-0.5)/0.5\n",
        "                         std=[0.5, 0.5, 0.5]),\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], # Coge cada valor X (que va de 0 a 1 después de haber aplicado el ToTensor) y hace la siguiente ecuación para convertir valores entre -1 y 1: (x-0.5)/0.5\n",
        "                         std=[0.5, 0.5, 0.5]),\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxylhJU1c8Lz",
        "outputId": "f52d9ff1-7945-4362-cbb7-346fbbb88abe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape del set de Train: 2637\n",
            "Shape del set de Test: 660\n",
            "Shape del set del Dataset: 3297\n",
            "Shape del tensor de imágenes: torch.Size([44, 3, 224, 224])\n",
            "Shape del tensor de labels: torch.Size([44])\n"
          ]
        }
      ],
      "source": [
        "# Aplicamos las transformaciones diseñadas en el paso anterior\n",
        "\n",
        "# train_dataset.dataset.transform = transform_train --> Esto lo haríamos en caso de que el train_dataset aún NO fuese instancia de ImageFolder (e.g., cuando se utiliza random split para dividir el dataset)\n",
        "# test_dataset.dataset.transform = transform_test\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=path_train, transform=transform_train)\n",
        "test_dataset = datasets.ImageFolder(root=path_test, transform=transform_test)\n",
        "\n",
        "# Creamos un loader para configurar los batches, un batch_size de 44 significa que utilizamos lotes de 44 imágenes, donde todas las imágenes de cada lote se ejecutan a la vez.\n",
        "# Esto nos permite que el gradiente se calcule de forma menos ruidosa, es decir, a la hora de recalcular los pesos para minimizar los errores, tendrá en cuenta el promedio del error (cuadrático?) de todas las imágenes, en vez de una sola imágen.\n",
        "# Si tenemos 132 imágenes y el tamaño de los batches es de 44, tendríamos un total de 3 batches para procesar todas las imágenes. Cuanto mayor sea el batch_size, mayor tardará en ejecutarse cada batch.\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=44, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=44, shuffle=False)\n",
        "\n",
        "# Leemos los batches de imágenes como tensores para después poder entrenar el modelo\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(\"Shape del set de Train:\", len(train_dataset))\n",
        "print(\"Shape del set de Test:\", len(test_dataset))\n",
        "print(\"Shape del set del Dataset:\", len(train_dataset) + len(test_dataset))\n",
        "print(\"Shape del tensor de imágenes:\", images.shape)\n",
        "print(\"Shape del tensor de labels:\", labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6rrGKMkif4v"
      },
      "source": [
        "**PUNTO 4.**\n",
        "\n",
        "\n",
        "*   Instanciamos una Deep Neural Network de ResNet (ImageNet), descargando los pesos preestablecidos por defecto del propio modelo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qctv5M70LugS",
        "outputId": "eb782588-7a0c-4e81-a813-9565b0e2ae93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 112MB/s]\n"
          ]
        }
      ],
      "source": [
        "resnet18_model = models.resnet18(weights=\"DEFAULT\")  # pesos preentrenados de ImageNet\n",
        "num_features = resnet18_model.fc.in_features  # número de features de la última capa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSJRCgCZk-Yp"
      },
      "source": [
        "**PUNTO 5.**\n",
        "\n",
        "\n",
        "*   Eliminamos las capas Lineales de la etapa clasificadora de la red neuronal y\n",
        "sobrescrimos con unas nuevas capas lineales con los mismos parámetros de\n",
        "configuración ajustadas a nuestra problemática\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pH1r7MlvlVDA"
      },
      "outputs": [],
      "source": [
        "# Reemplazamos la cabeza clasificadora.\n",
        "# La ResNet18 produce 512 features y 1000 clases en la última capa convolucional antes de llegar a las capas densas.\n",
        "# Nosotros tenemos que ajustar la salida a 512 features (lo dejamos como está) pero a 2 clases (Benigno vs Maligno)\n",
        "\n",
        "resnet18_model.fc = nn.Linear(num_features, 2)  # 2 clases: benigno vs maligno\n",
        "\n",
        "resnet18_model = resnet18_model.to(device) # Se entrena con la GPU o CPU, según lo que tengamos disponible"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ5Vh7ckmFNS"
      },
      "source": [
        "**PUNTO 6.**\n",
        "\n",
        "\n",
        "*   Realizamos el entrenamiento de la red neuronal configurada. (Con la nueva cabeza clasificadora) actualizando solo los pesos de las capas nuevas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSBK4IWHmvqh",
        "outputId": "a37ccd28-0264-49ee-bfd7-f0ea8327da4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 - Loss: 0.5193 - Accuracy: 0.7342\n",
            "Epoch 2/5 - Loss: 0.4410 - Accuracy: 0.7835\n",
            "Epoch 3/5 - Loss: 0.3874 - Accuracy: 0.8187\n",
            "Epoch 4/5 - Loss: 0.3878 - Accuracy: 0.8225\n",
            "Epoch 5/5 - Loss: 0.3690 - Accuracy: 0.8335\n"
          ]
        }
      ],
      "source": [
        "# Solo entrenaremos los parámetros de la nueva cabeza clasificadora (el que decide si es Benigno o Maligno)\n",
        "for param in resnet18_model.parameters():\n",
        "    param.requires_grad = False # No queremos que el modelo (capas convolucionales y capas densas) reajuste sus pesos, ya que es un modelo preentrenado\n",
        "for param in resnet18_model.fc.parameters():\n",
        "    param.requires_grad = True # Solo queremos reajustar la parte final, la cabeza clasificadora\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # Aplicamos CrossEntropyLoss para ajustar los pesos y reducir el loss\n",
        "optimizer = optim.Adam(resnet18_model.fc.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 5  # Vamos a utilizar 5 epochs (iteraciones completas) para entrenar al modelo. 5 Epochs y (2637/44) batches. En cada batch y cada epoch los pesos se reajustan.\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    resnet18_model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad() # Reseteamos los gradientes en cada batch para que no se vayan acumulando. Esto evita que los gradientes se vayan inflando de forma masiva.\n",
        "        outputs = resnet18_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR4UYPg6oEzo"
      },
      "source": [
        "**PUNTO 7.**\n",
        "\n",
        "*   Determinamos las métricas de función de pérdida (loss) y precisión para los conjuntos de datos de entrenamiento y test.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YfNCJvmCpBWW",
        "outputId": "d3ea0b04-9be6-4526-ad60-2c50a604faea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.4360 - Test Accuracy: 0.8242\n"
          ]
        }
      ],
      "source": [
        "resnet18_model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = resnet18_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        test_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_loss /= total\n",
        "test_acc = correct / total\n",
        "print(f\"Test Loss: {test_loss:.4f} - Test Accuracy: {test_acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtZh//tM4ajvDFCseyHx0R",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}